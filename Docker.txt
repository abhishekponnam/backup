================================================================================================================
   Docker  &&  Kubernetes
====================

Application Development :
+++++++++++++++++++++

=> Collection  of  programs  is  called   as   software  project .
=>  Software  project  contains  several  components 

		1) Front end  Components
		2) Backend   components
		3) Database  components 
=> In order  to deploy  our  application  in  a  machine  we  need to  setup  all  the   softwares  which  are  required   to our   application

		Ex : OS , JAVA 1.8v , MYSQL  DB , Tomcat websever  9.0v  ....etc

=> In real time projects should be deployed  for testing  purpose.
		
	DEV :-  Dev env is used  by  developers  to  perform  the  integration  testing
	SIT  :-   SIT  env  is  used  by testing  Team  to  test  the  functionality  of  an  application.
	UAT :-  User  Acceptance Testing  env  will  be  used  by  client  to  test  the  functionality  of  the  application.
	PILOT :- PILOT  env  means  pre-production  testing  env
	PROD  :-  PROD  env  means  live  Environment ( It  is  used  to deliver  the  project )


=> To  deploy  application  to  many  environments  we  need  to  take of  all  the  softwares  required  to  run  our application in  all  environments . It  is very difficult task.



Virtualization
++++++++++++

=> Installing multiple  guest OS in one host Operating   System.
=> Hypervisior  S/W will be  used to  achieve  this
=>  we need  to  install  all  the  required  softwares  in HOST  OS  to  run  our  applications.
=> It  is  old technique  to  run  the  applications.
=> System performance  will become  slow.
=> To Over Come  the problems  of Virtualization  we  are going  for containerzation.


Containerization
++++++++++++++
=> It is  used  to package all the softwares  and application  code in  one container for Execution.
=> Container will take care of everything which  is  required  to  run  our  application.
=> we can run the container in Multiple Machines easily.
=> Docker is  containerization  software.
=> Using Docker s/w we will  create Container  for  Our application.
=> Using Docker  we  will create an Image  for our Application.
=> Docker images  we  can share  easily  to  Multiple  Machines.
=> Using  Docker  Image  we  can  create  the docker  Container  and  we can Execute  it.
=> It is  easily Shippable. 


Conclusion : 
	We  can  Say that Docker will take Care  of  Application  and  application Dependencies  for  Execution. 
	Deployments  into Multiple  environment  will become  easy  if  we  use  the  docker  Concept.



+++++++++Install  Docker  in  Amazon  Linux ++++++++++++

$  sudo  yum  update  -y
$  sudo  yum  install  docker  -y
$  sudo  service  docker  start

#  add  user  to docker  group  by executing  below  command
$  sudo  usermod   -aG  docker  ec2-user

$  docker  info

# Restart the  session 
$  exit 

Then  press 'R'  to  restart  the  session ( This  is  MobaXterm ).



+++++++++Docker  Commands +++++++++++++++
 
# see Docker  info
$ docker info

# To see  docker images  execute the below  command
$  docker  images

# Pulling  the hello-world  docker  image
$  docker  pull  hello-world

# then see again the docker  images
$  docker images

# Running  hello-world  docker  image
$  docker  run  hello-world

Note :  Create  account  in Docker Hub ( https://hub.docker.com)



DOCKER  TERMINOLOGY
====================

1) Dockerfile
2) Docker Image
3) Docker Container
4) Docker  Registry
5) Docker  Engine


Docker File :-  Dockerfile  contains  instructions  to  Create  an  Image . It  Contains  Docker  Domain  Specific  keywords 		to  build  Image.

Docker Image :- Docker Image  is  a  package which  contains  Everything  (App  code + softwares + env + Libraries ).

Docker  Container  is  Runtime  Instance  of  Docker  Image , Our application will Run  in  the container .

Docker  Registry  is  a  place  where  we  can  store  Our  Docker  Images.

Docker engine  is  a software using which we will  create Docker Images  and Docker  Container.
		Docker 


=> Docker   Hub  is  a public registry . everyone Can Retrive the Images 
=> Nexus, JFrog , D.T.R , AWS Elastic Container Registry is private. ( Company Specific).

how to Make  the Docker File  in LINUX
+++++++++++++++++++++++++++++++

$ vi Dockerfile 

--insert--

FROM  ubuntu
RUN  echo "Run  One Updated "
RUN  echo "Run TWO"
RUN  echo  " Echo from  Image "
RUN  echo  "Echo  from  latest"
RUN  echo  "RUN  three"

# build docker image using Docker file
$ docker  build  -t  <file-name> 

# login through you Linux into Docker acccount
# Tag the  Docker Image 
$  docker  tag   <file-name >   <repo/name>


# Push  docker  image
$  docker  push  <reponame>



++++++++++
DockerFile
++++++++++
=> DockerFile  Contains Instructions  to  Build  docker  Image.
=>  In DockerFile  we use  DSL (Domain Specific Language ) Keywords.
=> Docker  Engine  will  process  Dockerfile  instructions   from   top  to  bottom.
=> Below  DockerFile  Keywords

FROM :-
=====
	it  indicates  base  image  to  run  our  application . On  top   of  base  image  we  will create own  image.
	
	syntax :  FROM  <Image-Name>
	Ex:-
		FROM  java:jdk-1.8
		FROM  tomcat:9.2
		FROM  mysql


MAINTAINER
==========
=> Who is the Author of the Docker File.
Example :-
	 MAINTAINER   abhishek <abhishekp5510@gmail.com>




COPY
====
=> it is used  to  copy files/folder  to  image while  creating image.

Syntax :-  COPY  <source> <destination>

Example :- 
# copying the war from target directory  to  tomcat /webapp  directory
 
	COPY  target/maven-web-app.war    /usr/local/tomcat/webapp/maven-web-app.war

ADD 
===
=>ADD  is  used  to  copy  files  to image  while  creating  an Image.
=> ADD  Keyword can  download  files  from  remote location (http)
=> ADD  Keyword  will  extract  tar  file while  copying to  image.

Note : For Zip file we need  to extract it separetly.

SYNTAX :

ADD <source >  <destination>
ADD <url-to-download> <destination>

Q) what  is  difference  between  COPY  and  ADD ?



RUN
====
=> RUN  commands  will  execute  commands on  top  of  base  image.
=> RUN  command  instructions  will  execute  while  creating  an  image.
=>  We can  write multiple  RUN  instructions , they  will  execute in order (top -  bottom)

Example :

RUN mkdir  workspace
RUN  yum  install  git



CMD
====
=> CMD  is  also  used  to  execute  commands.
=> CMD  commands  will execute  while  creating  Container.

Example :

CMD  sudo  start tomcat

=> We  can  write  multiple  CMD  instructions  in  Docker file  but  Docker  will  process  only  last  CMD   instruction.

**Note :-
	 there  is  no use of  writing  multiple  CMD  instructions  in  Dockerfile. Only  Last  CMD  command  will  Execute.

Sample Dockerfile 
++++++++++++++++

FROM  ubuntu
RUN   echo "run one"
RUN  echo " run  two"
CMD  echo "cmd  one"
CMD  echo "cmd  two"
RUN  echo "run  three"

# build  image from file 
$ docker  build  -t  imageone  .

# run  the image
$  docker  run imageone

**Note :-   CMD  instruction  we   can  override  using  runtime CMD.

#It  will  print  only  date (CMD  will not  execute)
$  docker  run  imageone  date


#if  we  want  to  change the dockerfile  name
$  mv  Dockerfile  Dockerfile_one

#Creating  the Docker  image for the  Dockerfile_one
$  docker  build  -f   Dockerfile_one  -t  imagetwo  .  
 

ENTRYPOINT
===========
=> ENTRYPOINT   instruction  will  execute  while  creating  container.

**Note :-  CMD  instructions  we  can  override  where  as  ENTRYPOINT  instructions  we    can't  Override.

Example :-

ENTRYPOINT  ["echo","Welcome  to AshokIT"]



WORKDIR
========
=> It is used  to  set  Working  Directory  for  an  Image /Container.

Ex: WORKDIR <DIR-PATH>

Note : The  Dockerfile  instructions  which  are  available  after  WORKDIR  those  instructions  will  be  process  from  given  working  directory.

 

 
ENV
====
=> ENV   is  used  to  set  Environment  variables

Ex :  ENV  <key> <value>


LABEL
=====
=> It is used to add   meta  data for  our  image.
=> LABEL  will  represent  the  data  in  Key-value  pair.

Ex:  LABEL  branchName  release


ARGS
=====
=> It  is  used  to  avoid  hard  coded  values  in  Dockerfile.

Ex: 

ARG  branch = develop
LABEL branch  $branch

**Note :-  we can pass values  at  runtime.

$  docker  build  -t  imageone  --build-arg  branch= feature

USER
====
=>  We  can  set  user  for  an  image / container

Note :  After  USER  instruction , remaining  instructions  will  be  processed   with  given  USER.


EXPOSE
======
=> It  represents  on  Which  port number  our  container  is  running.
=> It  is  just like  a documentation  to  understand   container  running  port  number.


VOLUME
=======
=> it  is  used  for  data  storage




++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Dockerizing  Spring  Boot  Application
++++++++++++++++++++++++++++++

FROM  java:8-jdk-alpine
COPY  ./target/springboot-docker-app.jar   /usr/app/
WORKDIR  /usr/app
RUN  sh  -c  'touch springboot-docker-app.jar'
ENTRYPOINT ["java","-jar","springboot-docker-app.jar"]


++++++++++++++++++++++
Dockerizing  JAVA  web APP
++++++++++++++++++++++

FROM  tomcat: 8.0.20-jre8
COPY   target/java-web-app*.war  /usr/local/tomcat/webapps/java-web-app.war

Note : After  running  the  container  access  application using  below  URL.

URL : http://ec2-vm-public-ip:8080/java-web-app


+++++++++++++++++++++++++++++++
Dockerizing Python  Flask  Application
+++++++++++++++++++++++++++++++

FROM  python:3.7
WORKDIR   /opt/app
COPY  .  .
RUN  pip  install   --no-cache-dir  -r  requirements-prod.txt
EXPOSE  5000
CMD ["python3", "-m","flask","run","--host=0.0.0.0"]

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

NOTE :-

#to  see  the  docker  images
$ docker images 

#to  see the  docker  containers
$ docker  ps

# To  remove  the  image
$  docker  rmi  <image-id>


=> first  we  need to  stop  the  container then remove the containers

#Docker   stop  the  containers
$ docker  stop  <container-id>

#To  remove  the  container
$  docker  rm  <container-id>


=>  after  deleted  container  see exited container cache and delete it 
$ docker  ps  -a

# to delete stoped containers and unused  images and the cache  images
$ docker  system prune  -a

* above command  will remove  
=> all the stopped  containers
=> all  networks  not used  by  at least  one  container
=> all  images  without at  least one  container  associated  with  them.
=> all  build  cache


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

DOCKER  VOLUMES
+++++++++++++++

=> Docker Volumes  are  used  to  persist  the  data  generated  by  Docker  Containers.
=> Using  docker  volume  we  can  de-couple   data  storage   from  docker  containers
=>  using  Docker Volume we  can  share  the  data among  multiple  containers.
=> On deletion of   container  Docker  Volume  will  not  be  deleted.

#Docker  Volume


#To  display Docker  volume  commands
$ docker  volume  --help

#Create  the  Docker  Volume
$  docker volume  create  <volume-name>

#Display  the  Docker  volumes
$  docker volume ls

#Inspect  the  volume
$ docker  volume  inspect  <volume-name>

#Remove  docker  volume
$  docker  volume  rm  <volume-name>

#Remove  unused  volume
$  docker volume  prune

#Run the docker images to form 
$   docker  run  -d  -p <host-port>:<container-port>  <image-name>
$  docker  run     -d  -p  80:80  ngnix

-d => represents  detached mode . it means after execution of the above command we can execute another commands also.
-p => for the port mapping from host machine to container port.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Docker volume LAB
++++++++++++ ++++

* We  are making two  containers.  
*  connecting container1  to  Docker Volume  and  Store  data . 
* Then delete that  container1. 
* Connect the container2  to existing Docker Volume  and  Fetch  the  data.


commands
=========

#pulling ngnix  image  from  dockerhub
$  docker  pull ngnix

#Running  ngnix  image  using docker  container with  container  name  as "webapp1"
$  docker  run  --name=webapp1   -d  -p  80:80  ngnix

Note :- here Access  static  website  using  EC2 VM  public  IP  which is hosted  by Ngnix



# Modify  the  static   website using  EC2  VM  public  IP  which   is  hosted  by  ngnix.
$  docker  exec  -it  webapp  bash
$  cd  /usr/share/ngnix/html
$  ls -l
$  echo  "Welcome  to World " > index.html

Note :- here Access  static  website  using  EC2 VM  public  IP  which is hosted  by Ngnix( here modified content will be displayed)


#Stop  docker Container Which  is  "WebApp1"
$ docker  stop  <container-id>  





#Running  ngnix  image  using docker  container with  container  name  as "webapp2"
$ docker  run  --name=webapp2  -d  -p  80:80  ngnix

Note :- here Access  static  website  using  EC2 VM  public  IP  which is hosted  by Ngnix.
( here modified content will not  reflect  here)

# same ngnix  will  run not the changed  content.
$ docker  stop  <container-id>

=> Hence here data is not stored in container when we stoped and started and another container can't access the data of the other containers.

+++++++++++++++++++++++++++++++++++++++++++++++++++

# Create a Docker Volume 
$ docker  volume  create  new_vol

# Mounting the Docker volume to new webapp20
$ docker  run  -d   --name=webapp20  --mount   source=new_vol, destination= usr/share/ngnix/html   -p  80:80  ngnix


# Modify  the  static   website using  EC2  VM  public  IP  which   is  hosted  by  ngnix.
$  docker  exec  -it  webapp  bash
$  cd  /usr/share/ngnix/html
$  ls -l
$  echo  "Welcome  to World " > index.html

#Stop the container of webapp20
$ docker  stop  <container-id>


#Mount  the  existing  Docker Volume  to  new  webapp21 ( The  modified  content  will be  printed.)
$ docker  run  -d   --name=webapp21  --mount   source=new_vol, destination= usr/share/ngnix/html   -p  80:80  ngnix

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Host Directory  Mounting  to  Docker  Container (Bind MOUNT Concept)
+++++++++++++++++++++++++++++++++++++++

=> It is  used  to map the EC2  directory to store data  with Docker container ( without using docker Volume)

#Create  the  directory  in host machine
$ mkdir  -p  /tmp/nginx/html

# Run Docker  container  for  ngnix  image  with directory  mounting ( Container name  as C1)
$ docker  run  -d  -p  80:80  -v  /tmp/ngnix/html:/usr/share/ngnix/html  --name  c1  ngnix:latest

Note : -v  represents the volume

# See the container which are  running (C1 should be  running) 
$ docker  container  ls


Note :- Access the ngnix  server with host machine  Public  IP ( it will be not  displayed because index.html is not present in  container )

# go to mounted directory  in host Machine
$ cd  /tmp/ngnix/html

# Create the html file
$ vi  index.html

Note : Write the  content  in index.html  file then  save  it  close it

=> Access Ngnix  webserver  in  browser (Changes  will be  reflected)

Note :  we have  created  index.html  file  in  host  machine  mounted  directory.




+++++++++++++++++
Docker   Compose
+++++++++++++++++

=> In real World  applications  are  getting  developed  using  Microservices  architecture.
=>  In Microservices  architecture  the  several  apis  are available.
=>  Every  API  is  project that should be  run in a container.
=> Running  the  multiple container manually  for  all  API's  is  difficult Job.
Note :-  To  solve  the above problem the Docker Compose is introduced.

=> Docker Compose   is  a tool  which  is  used to manage  multi  container  based  applications.
=> Using Docker  compose we can  define & deploy  multi container  based  applications.

=> We will give input to  docker  compose  using  YAML  file  to  run  multiple  containers. 
=> Docker  compose  YML  file  should have  information  related  to  all  our  services.



Sample Docker Compose YML(docker-compose.yml)
===========================================

version :

services:

network:

volumes:

=> Docker Compose Default File name : docker-compose.yml

#create  and  start the containers
$ docker-compose up

#List the docker containers that are started by  docker compose
$ docker-compose  ps

# stop and remove the containers
$ docker-compose  down

#list down running  container  images
$ docker-compose  images

#if the name of docker compose is changed
$ docker-compose  -f  <file-name>  up


Docker Compose setup in EC2
+++++++++++++++++++++++++

# download the docker  compose
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose

# give the permission
sudo chmod +x /usr/local/bin/docker-compose

# Check the version of docker-compose and installed or not 
docker-compose version


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Create  a docker  compose  file  for setting  up  dev environment. MYSQL  container linked with wordpress  container
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

version: '3.8'
services:
  mysql:
    image: mysql:5.7
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: my-secret-password
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    ports:
      - 3306:3306
    volumes:
      - mysql_data:/var/lib/mysql
  wordpress:
    image: wordpress:latest
    container_name: wordpress
    depends_on:
      - mysql
    environment:
      WORDPRESS_DB_HOST: mysql
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    ports:
      - 8080:80
    volumes:
      - wordpress_data:/var/www/html
volumes:
  mysql_data:
  wordpress_data:


# Lets  remove  all  the  running  container.
$ docker  rm  -f  $(docker  ps  -aq)

# How  to  start  the above  services  from  yml  file
$  docker-compose  up

# We  got  lot of logs  coming  on the  screen . to  avoid  it  we  use  -d  option
$  docker-compose  stop

# Remove the  container
$  docker  rm  -f  $(docker  ps  -aq)

#Run  container  in  detached  mode
$  docker-compose  up  -d

#to check  wordpress  site
URL :  http://public_ip:9090

# to  stop both  the  containers
$  docker-compose   stop


+++++++++++++++++++++++++++++++++++++++++++++
Spring boot  APP  with  MySQL  DB  using   Docker  compose
+++++++++++++++++++++++++++++++++++++++++++++

=>  To  run  springboot   application  we  will use  below  Dockerfile

FROM   openjdk : jdk1.8
COPY    target/sb-app.jar    /usr/local/sb-app.jar
WORKDIR   /usr/local/
EXPOSE   5000
ENTRYPOINT ["java","-jar","sb-app.jar"]

=> if  we  are  using  MySQL  DB  in  springboot   application  then  we need  to MySQL  DB  in  a  container.

Note : Instead  of  Managing  two  containers  separatley  we can use  Docker  compose.


Docker  Compose  Configuration  (docker-compose.yml)
--------------------------------------------------------------------------

version : "3"

services: 

    boot-app:
            image: sb-rest-api
            ports :
                    -"8080" :  8080
             depends_on:
	-mysql-db

    mysql-db:
              image : mysql:8
              environment  :
                -MYSQL_ROOT_PASSWORD = root
                -MYSQL_DATABASE =  bootdb



++++++++++++++++
DOCKER  NETWORK    
++++++++++++++++

=> Networking  is  about  communication  among  processes.
=> Docker Networking  enables  a  user   to  link  a  docker  container  to as  many  networks  as they  require.
=>  Docker  network  is  used  to  provide  complete  isolation  for Docker  container

Advantages  of  Docker  Networking
===========================

=> They  share  single  operating  System  and  maintains  containers  in  isolated  Manner.
=> It  requires  few  OS  instance  to  run  the workload.
=> It helps in  fast  delivery  of the  software.
=> It  helps  in  application  portability.


* When   Docker  S/W  is  installed   in  a machine   by  default   3  docker networks  will  be  configured
		
		1) None
		2) Host
		3) bridge

**Note : One  container can be  attach to multiple networks.

* When  Container  is  attached   to  multiple  networks  then  those  containers  can  communicate.
*  Docker providing  Networking  to  containers  using  Network  Drivers.


Docker Network Drivers
+++++++++++++++++++

1) Bridge

2) Over 

3) None

4) Overlay

5)  Macvlan  


Bridge :
======
=>  This  the  default  network  drive  created  on  Docker  host  Machine.

**Note : Bridge network  drivers  are very  useful  when  application  running  on  Standalone container.

# we  can  see  more  details   about  bridge  driver below  command
$  docker  network  inspect  bridge


Host Drivers:
==========
=> It  is  useful  when the standalone  container  is  available.
=> The  container  will  not  get  any  IP  address  when  we  enable  Host  Drivers.

Note : For  example  a  container  is  executed  that  binds  to  port 80  with  host  network  driver. in this  case  we no need   to  map  container port to host machine port.

=> this  is  useful when  we  are  running  our  containers with  large  no.of  ports.



None  Drivers
============

=> In  this  type of  network, the  containers  will have no  access  to network.


Overlay Drivers
=============
=> we  will use  Docker  Swarm  to  orchestrate  our Docker  container.
=> Overlay  driver  will be  used  when  we have  Docker  swarm cluster.


Macvaln Driver
=============
=> This network  driver  will  assign  a  MAC  address to  a  container.
=> MAC  address  will make  our  device  as  Physical.
=> Using  this  MAC  address  Docker Engine  routes  the  traffic  to  particular  route.
=> Macvaln  Driver  simplifies  communicaton  between  container.




++++++++++++++++++++++++++++++++++++++++
Working with Docker  Networking  Commands
++++++++++++++++++++++++++++++++++++++++

# List  all networks
$ docker network ls

#Running  docker  container  with  default  network
$ docker  run  --name  ngnix -d  -p  80:80  ngnix

$  docker inspect  ngnix


# Creating  our  own network
$  docker  network  create  --driver  bridge my-network

**Note : if  we  don't  specify  driver then by  default it  will take  bridge  driver.

# Run the docker  container using  custom network  which  we  have  created.
$  docker  run  --name  ngnix  ngnix20  -d  --network  my  network  -p 7070:80  ngnix


# Check the  containers  attached  to  my-network
$  docker  network  inspect  my-network

+++++
LAB
+++++

# Run 2  containers using  my-network  and  check  connectivity  between  2  containers  using  ping  command.

# creation of container 30
$  docker  run  --name  ngnix  ngnix30  -d  --network  my  network  -p  8080:80  ngnix
# creation  of  container 31
$  docker  run  --name  ngnix  ngnix31  -d  --network  my  network  -p  9090:80  ngnix

# Check the containers
$  docker ps


# Get  the IP  address of  Docker  container
***Syntax :  $  docker  inspect  -f  '{{range.NetworkSettings.Networks}} {{.IPAddress}}{{end}}'  <container-id>    ( or <container-name>)


#get the IP of ngnix30
$ docker  inspect  -f  '{{range.NetworkSettings.Networks}} {{.IPAddress}}{{end}}'  ngnix30

## 172.19.0.2

# get the IP of ngnix31
$ docker  inspect  -f  '{{range.NetworkSettings.Networks}} {{.IPAddress}}{{end}}'  ngnix31

## 172.19.0.3


# Change the host to container 
$  docker  exec  -it  ngnix30  /bin/bash


# update the packages in container ngnix30
$  apt-get   update

# install  ping  command
$ apt-get  install  iputils-ping


# ping the 31 container from 30 container
$ ping  172.19.0.3

*** Hence the ping will execute so both of the containers  are in same network named (my-network)


# Change the host to container 31
$  docker  exec  -it  ngnix31  /bin/bash


# update the packages in container ngnix31
$  apt-get   update

# install  ping  command
$ apt-get  install  iputils-ping


# ping the 30 container from 31 container
$ ping  172.19.0.2


Ngnix30  Container IP : 172.19.0.2
Ngnix31  Container IP : 172.19.0.3




+++++++++++++++++++++++++++++++++++++++++
Running  Network Using  Host Network  Driver
+++++++++++++++++++++++++++++++++++++++++

=> When we  use host  network  driver port mapping  is not  required.

$ docker  run  --name ngnix35  --network  host  -d  ngnix

**Note :  if you  observe  we  are  running  ngnix  container without  port  mapping because we  are using host  network  driver.




+++++++++++++++++++++++++++++++++++++++++++++
Running  Containers  using  Macvlan network  driver
+++++++++++++++++++++++++++++++++++++++++++++


In  Docker  a  common  question  that  usually  comes up   is "How  do  I expose my  containers directly  to my  physical network? " . This  is specially  so  when  you are  running  monitoring  applications  that  are  collecting  network statistics  and  want  to  connect container  legacy  applications . A possible  solution  to  this  question  is  to  create  and  implement  macvlan  network  type.

Macvlan  networks   are  special  virtual  networks  that  allows you  to  create "clones"  of  the physical  network  interface  attached  to  your linux  servers  and  attach  containers  directly  your  LAN. To  ensure this  happens,  simple 
designate  a physical  network  interface on  your  server  to  a macvlan  network  which  has  its  own  subnet  and  gateway.

#get the ip address of host  machine
$  ipconfig

take  ip address  from eth0

inet :172.31.13.126

CIDR  Block (subnet) : 172.31.13.0/24

Gateway : 172.31.13.1

# Create the macvlan network  using  subnet and  gateway
$  docker network  create  -d   macvlan \
      --subnet = 172.31.13.0/24 \
      --gateway= 172.31.13.1 \
      -o  parent=eth0 \
        demo-macvlan-net

# check the network  is  created 
$ docker  network  ls

# inspect  the  docker  network  check the container  associated with that
$  docker  network  inspect  <container-id>

#Run  the  docker  container  using  macvlan  network  we have  created
$  docker  run  --rm  -itd\
--network = demo-macvlan-net\
--ip=172.31.13.110\
alpine:latest \
/bin/sh

# inspect network  created
$  docker network  demo-macvlan-net 


+++++++++++++
Docker  Swarm
+++++++++++++

=> Docker  Swarm  is  an  orchestration  tool  provided  by  docker  software.
=> Orchestration  means  managing  process/containers.
=> Docker  Swarm   is  used  to  setup  Docker  cluster( load balancing).
=> Docker  Swarm  is  embedded  in  Docker Engine.
=> Cluster  means  group of  servers
=> We  will  setup  master  and worker  nodes in  docker swarm  cluster.

=> Master  will  schedule  the  tasks(containers)  and  manage  the nodes  and  node  failures.
=> Worker  nodes  will perform  the  action (container will run here)


Swarm  features
=============
1) Cluster  Management
2) Decentralize  design
3) Declarative  service  model
4) Scaling
5) Multi Host  Network
6) Service  Discovery
7) Load  Balancing
8) Secure  by  default
9) Rolling  updates

setup
++++

-> Create 3  EC2  instances (ubuntu)
Note : Enable  2377  port for swarm  Cluster  communications

$ curl  -fsSL  https://get.docker.com  -o  get-docker.sh
$ sudo sh  get-docker.sh

1-master
2-Nodes

-> Connect  to master Machine  and  execute  below  command (1st  time)
$  sudo docker  swarm  init --advertise-addr  172.31.38.222(private ip of  EC2 instance)

   after executing above command then host machine  will  genrate a command  to paste in nodes to  work as workers.

Sample command will be generated :-
	$ sudo  docker  swarm  join  --token <token-id>  172.31.38.222:2377

# use  to add multiple managers to aviod the master failure ( after 1st any time below command)
$  sudo  docker  swarm  join-token  manager

# add  workers to master swarm
$  sudo  docker  swarm  join-token  worker

Q) What  is  docker  swarm  manger  quarm?
Ans) if  we  run only  2  masters  then  we can't  get  gaurantee   high  availabilty  for  the  application

Formula : (n-1)/2

if  we  take  2  master servers

2-1/2  = 0.5 (it  can't become master)
3-1/2 = 1 (it can be a leader when main leader is down)

note : Always  use odd number  for  master machines  when  we  are using  docker swarm  cluster.

-> if  we  use "docker  run"  command then  our  applicaton will  be exectued in one container.
-> In  Docker  Swarm  we need  to  deploy  our  application  as  a service.

Docker  Swarm  Service
++++++++++++++++++
->  Service  is  collection of  one or more  container  of same  image.

=> There  are  two types  of  services  in  docker  swarm

1) Replica (default  mode)
2) global


$ sudo  docker  service  create  --name <service-name> -p  <hostPort>: <containerPort> <imageName>

$ sudo docker  service   create --name  java-web-app  -p  8080:8080  ashokit/javawebapp

Note : By  deafault  1  replica  will be  created

# Check the  services  created
$  docker  service  ls

#we  can  scale  docker  service
$  docker  service  scale <serviceName> = <no.of.replicas>

#inspect the docker  service
$  sudo docker  service inspect --pretty java-web-app

# see  service  details
$  sudo  docker  service ps  java-web-app

# remove  one  node   from swarm  cluster
$  sudo  docker  swarm leave
